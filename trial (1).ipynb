{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7496052,"sourceType":"datasetVersion","datasetId":4364753},{"sourceId":7497750,"sourceType":"datasetVersion","datasetId":4365867},{"sourceId":7497869,"sourceType":"datasetVersion","datasetId":4365951},{"sourceId":7504214,"sourceType":"datasetVersion","datasetId":4370044}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-29T09:12:33.584560Z","iopub.execute_input":"2024-01-29T09:12:33.585119Z","iopub.status.idle":"2024-01-29T09:12:35.483913Z","shell.execute_reply.started":"2024-01-29T09:12:33.585088Z","shell.execute_reply":"2024-01-29T09:12:35.482918Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/updated-data/hello.csv\n/kaggle/input/bert-base-multilingual-epoch-18/bert-base-multilingual-uncased-False-18.pt\n/kaggle/input/evalsem24/MaSaC_test_erc.json\n/kaggle/input/mbert-l3-cube-epoch-9/hing-mbert-False-9.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install ml_collections wandb\n!wandb login dedc08f0b13e84705452beca60fc2b5f46430ff9","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:12:35.485799Z","iopub.execute_input":"2024-01-29T09:12:35.486320Z","iopub.status.idle":"2024-01-29T09:12:58.216181Z","shell.execute_reply.started":"2024-01-29T09:12:35.486284Z","shell.execute_reply":"2024-01-29T09:12:58.215073Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting ml_collections\n  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m812.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from ml_collections) (1.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml_collections) (6.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from ml_collections) (1.16.0)\nCollecting contextlib2 (from ml_collections)\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.32)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.39.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.1.2)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nBuilding wheels for collected packages: ml_collections\n  Building wheel for ml_collections (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ml_collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=6d59328faa890d851a6eb334ddd46e71cf588cecd8a7ba854da9880b27b830b3\n  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\nSuccessfully built ml_collections\nInstalling collected packages: contextlib2, ml_collections\nSuccessfully installed contextlib2-21.6.0 ml_collections-0.1.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport wandb\nimport warnings\nimport random\nimport pandas as pd\nimport numpy as np\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom datetime import datetime\nfrom ml_collections import ConfigDict\nfrom transformers import AutoModel, AutoTokenizer\nfrom tqdm import tqdm\nfrom sklearn.metrics import classification_report,f1_score","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:12:58.217761Z","iopub.execute_input":"2024-01-29T09:12:58.218129Z","iopub.status.idle":"2024-01-29T09:13:10.068643Z","shell.execute_reply.started":"2024-01-29T09:12:58.218083Z","shell.execute_reply":"2024-01-29T09:13:10.067856Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel, AutoTokenizer\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import classification_report, f1_score\nfrom ml_collections import ConfigDict\nfrom torch.utils.data import DataLoader, Dataset\n\ntorch.manual_seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(42)\n\ncfg = ConfigDict()\ncfg.model_name = \"bert-base-multilingual-uncased\"\nemotion_mapping = {\n    \"disgust\": 0,\n    \"contempt\": 1,\n    \"anger\": 2,\n    \"neutral\": 3,\n    \"joy\": 4,\n    \"sadness\": 5,\n    \"fear\": 6,\n    \"surprise\": 7,\n}\n\nclass DialogueDataset(Dataset):\n    def __init__(self, test_data_path):\n        super().__init__()\n        self.dataframe = pd.read_csv(test_data_path)\n        self.label_mappings = emotion_mapping\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        utterance = self.dataframe[\"utterances\"].to_list()\n        return utterance[index]\n\n    def create_loader(self, batch_size):\n        return DataLoader(self, batch_size=batch_size, shuffle=False)\n\nclass SemEvalNet(torch.nn.Module):\n    def __init__(self, model_name, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.backbone = AutoModel.from_pretrained(model_name)\n        self.linear_layer = torch.nn.Linear(768, self.num_classes)\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.push_to_device()\n\n    def forward(self, batch):\n        x = self.backbone(**batch).pooler_output\n        x = self.linear_layer(x)\n        return x\n\n    def push_to_device(self):\n        self.backbone.to(self.device)\n        self.linear_layer.to(self.device)\n\n    def predict(self, test_loader):\n        predictions = []\n        self.eval()\n        with torch.no_grad():\n            for batch in tqdm(test_loader):\n                inputs = self.tokenizer(\n                   text=list(batch),\n                   return_attention_mask=True,\n                   max_length=256,\n                   padding=\"max_length\",\n                   truncation=True,\n                   return_tensors=\"pt\",\n                )\n                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n                scores = self(inputs)\n                predictions.extend(scores.argmax(dim=-1).cpu().numpy())\n        return predictions\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:10.071367Z","iopub.execute_input":"2024-01-29T09:13:10.071855Z","iopub.status.idle":"2024-01-29T09:13:10.147520Z","shell.execute_reply.started":"2024-01-29T09:13:10.071825Z","shell.execute_reply":"2024-01-29T09:13:10.146720Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Test data path\ntest_data_path = \"/kaggle/input/updated-data/hello.csv\"\n\n# Load test dataset\ntest_dataset = DialogueDataset(test_data_path)\ntest_loader = test_dataset.create_loader(batch_size=8)\n\n# Model instantiation\nmodel = SemEvalNet(model_name=cfg.model_name, num_classes=8)\nmodel.load_state_dict(torch.load(\"/kaggle/input/bert-base-multilingual-epoch-18/bert-base-multilingual-uncased-False-18.pt\"))  # Replace with the path to your model\n\nemotion_mapping_inv = {v: k for k, v in emotion_mapping.items()}\n# Make predictions\npredicted_labels = model.predict(test_loader)\n\n# Map predicted labels to emotions\npredicted_emotions = [emotion_mapping_inv[label] for label in predicted_labels]\n\n# Save predictions to a CSV file\npredictions_df = pd.DataFrame(predicted_emotions)\npredictions_df.to_csv(\"predicted_emotions.csv\", index=False)\n#{\"utterances\": test_dataset.dataframe[\"utterances\"],}","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:10.149014Z","iopub.execute_input":"2024-01-29T09:13:10.149440Z","iopub.status.idle":"2024-01-29T09:13:44.188143Z","shell.execute_reply.started":"2024-01-29T09:13:10.149403Z","shell.execute_reply":"2024-01-29T09:13:44.187262Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea79a2de85814ee3865bbf5f490b4975"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5fb873a7a134cea80edfcc0876df80e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6fea298186f4fbda3a19d24898fc84b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"308a5926ec304c59863bd73b84744b4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5b7c79990ec494e846640f3376fd334"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 198/198 [00:22<00:00,  8.88it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Length of utterances:\", len(test_dataset.dataframe[\"utterances\"]))\nprint(\"Length of predicted_emotions:\", len(predicted_emotions))","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:44.189417Z","iopub.execute_input":"2024-01-29T09:13:44.189786Z","iopub.status.idle":"2024-01-29T09:13:44.195786Z","shell.execute_reply.started":"2024-01-29T09:13:44.189753Z","shell.execute_reply":"2024-01-29T09:13:44.194665Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Length of utterances: 1580\nLength of predicted_emotions: 1580\n","output_type":"stream"}]},{"cell_type":"code","source":"df2=pd.read_csv(\"/kaggle/working/predicted_emotions.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:44.197104Z","iopub.execute_input":"2024-01-29T09:13:44.197406Z","iopub.status.idle":"2024-01-29T09:13:46.700769Z","shell.execute_reply.started":"2024-01-29T09:13:44.197366Z","shell.execute_reply":"2024-01-29T09:13:46.699814Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:46.701885Z","iopub.execute_input":"2024-01-29T09:13:46.702175Z","iopub.status.idle":"2024-01-29T09:13:46.723001Z","shell.execute_reply.started":"2024-01-29T09:13:46.702150Z","shell.execute_reply":"2024-01-29T09:13:46.722060Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"             0\n0      sadness\n1         fear\n2     surprise\n3      neutral\n4        anger\n...        ...\n1575   neutral\n1576   neutral\n1577       joy\n1578   neutral\n1579       joy\n\n[1580 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>surprise</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1575</th>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1576</th>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1577</th>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1578</th>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1579</th>\n      <td>joy</td>\n    </tr>\n  </tbody>\n</table>\n<p>1580 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#df2","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:46.724300Z","iopub.execute_input":"2024-01-29T09:13:46.725066Z","iopub.status.idle":"2024-01-29T09:13:46.729212Z","shell.execute_reply.started":"2024-01-29T09:13:46.725036Z","shell.execute_reply":"2024-01-29T09:13:46.728018Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#df1=pd.read_csv(test_data_path)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:46.732542Z","iopub.execute_input":"2024-01-29T09:13:46.732920Z","iopub.status.idle":"2024-01-29T09:13:46.740165Z","shell.execute_reply.started":"2024-01-29T09:13:46.732892Z","shell.execute_reply":"2024-01-29T09:13:46.739388Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#df1","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:46.741432Z","iopub.execute_input":"2024-01-29T09:13:46.741854Z","iopub.status.idle":"2024-01-29T09:13:46.751927Z","shell.execute_reply.started":"2024-01-29T09:13:46.741801Z","shell.execute_reply":"2024-01-29T09:13:46.750967Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#df3=pd.read_csv(\"/kaggle/working/predicted_emotions_batch16.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:46.753193Z","iopub.execute_input":"2024-01-29T09:13:46.753544Z","iopub.status.idle":"2024-01-29T09:13:46.763423Z","shell.execute_reply.started":"2024-01-29T09:13:46.753509Z","shell.execute_reply":"2024-01-29T09:13:46.762519Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#df3.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:46.764426Z","iopub.execute_input":"2024-01-29T09:13:46.764785Z","iopub.status.idle":"2024-01-29T09:13:46.775973Z","shell.execute_reply.started":"2024-01-29T09:13:46.764758Z","shell.execute_reply":"2024-01-29T09:13:46.775188Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#df4=pd.read_csv(\"/kaggle/working/predicted_emotions_batch32.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:46.777274Z","iopub.execute_input":"2024-01-29T09:13:46.778160Z","iopub.status.idle":"2024-01-29T09:13:46.789039Z","shell.execute_reply.started":"2024-01-29T09:13:46.778131Z","shell.execute_reply":"2024-01-29T09:13:46.788012Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#df4.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:46.790139Z","iopub.execute_input":"2024-01-29T09:13:46.790438Z","iopub.status.idle":"2024-01-29T09:13:46.799937Z","shell.execute_reply.started":"2024-01-29T09:13:46.790396Z","shell.execute_reply":"2024-01-29T09:13:46.799172Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#df5=pd.read_csv(\"/kaggle/working/predicted_emotions_batch64.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:46.801136Z","iopub.execute_input":"2024-01-29T09:13:46.801433Z","iopub.status.idle":"2024-01-29T09:13:46.811212Z","shell.execute_reply.started":"2024-01-29T09:13:46.801409Z","shell.execute_reply":"2024-01-29T09:13:46.810400Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#df5.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-29T09:13:46.812244Z","iopub.execute_input":"2024-01-29T09:13:46.812525Z","iopub.status.idle":"2024-01-29T09:13:46.822631Z","shell.execute_reply.started":"2024-01-29T09:13:46.812501Z","shell.execute_reply":"2024-01-29T09:13:46.821664Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}